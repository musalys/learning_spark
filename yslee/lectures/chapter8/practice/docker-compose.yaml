version: "3.9"
services:
  pyspark:
    build:
      context: .
      dockerfile: ../Dockerfile
      args:
        # These are build args for building pyspark docker image.
        # If you want build your own image, then replace below args with yours.
        # You can check spark_checksum with specific versions in https://archive.apache.org/dist/spark/
        # Also, if you want check image specifics when building docker image, please refer to https://jupyter-docker-stacks.readthedocs.io/en/latest/using/specifics.html#build-an-image-with-a-different-version-of-spark
        - spark_version=3.2.4
        - hadoop_version=2.7
        - spark_checksum=7b79d2b5b1816040a369d876072c9a9da132af1075b8523dcd24d3fde9a9afde70a73bbd5d1cbc428b233f6697c7969fea2ead4164b76fd1209a61a49fa260b9
        - openjdk_version=8
    platform: linux/amd64
    image: "pyspark-notebook/pyspark-jupyter-lab:${spark_version}"
    container_name: pyspark-jupyter-lab
    # user: root
    ports:
      # {HOST_PORT}:{CONTAINER_PORT}
      - 10000:8888
      - 9999:9999
    volumes:
      # Connect your local directory to pyspark with volumes
      - ~/Desktop/spark_study/LearningSparkV2:/home/jovyan/work
      - ./utils:/home/jovyan/work/utils
    # environment:
    # GRANT_SUDO: yes

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    platform: linux/amd64
    container_name: zookeeper
    ports:
      - 2181:2181
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - ./data/zookeeper/data:/data
      - ./data/zookeeper/datalog:/datalog

  kafka1:
    image: confluentinc/cp-kafka:latest
    platform: linux/amd64
    container_name: kafka1
    ports:
      - 9091:19091
    volumes:
      - spark_data:/data:rw
      - ./data/kafka1/data:/var/lib/kafka/data
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka1:19091,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9091
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CREATE_TOPICS: "raw:1:1"
    depends_on:
      - zookeeper

  kafka2:
    image: confluentinc/cp-kafka:latest
    platform: linux/amd64
    container_name: kafka2
    ports:
      - 9092:9092
    volumes:
      - spark_data:/data:rw
      - ./data/kafka1/data:/var/lib/kafka/data
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka2:19092,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    depends_on:
      - zookeeper

  kafka3:
    image: confluentinc/cp-kafka:latest
    platform: linux/amd64
    container_name: kafka3
    ports:
      - 9093:9093
    volumes:
      - spark_data:/data:rw
      - ./data/kafka1/data:/var/lib/kafka/data
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka3:19093,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    depends_on:
      - zookeeper

  kafka-ui:
    image: provectuslabs/kafka-ui
    platform: linux/amd64
    container_name: kafka-ui
    ports:
      - 8080:8080
    restart: always
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka1:19091,kafka2:19092,kafka3:19093
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    depends_on:
      - kafka1
      - kafka2
      - kafka3
volumes:
  spark_data:

networks:
  default:
    driver: bridge
