# 1장. 아파치 스파크 소개

## 스파크의 시작
- 빅데이터와 구글에서의 분산 컴퓨팅
  - 원활한 성능을 위해 GFS, MR, BigTable등을 만들게 됨.
  - GFS : 분산 파일 시스템
  - BigTable : 구조화된 대규모 데이터의 저장 수단
  - MR : 함수영 프로그래밍 개념을 기반으로 한 병렬 프로그래밍
- 야후에서의 하둡
  - GFS 논문에 자극받아 HDFS와 MR 탄생
  - 아파치로 이관되어 하둡 프레임워크의 일부가 됨.
  - MR의 문제점
    - 번거로운 운영 복잡도
    - MR API는 장황하고 많은 양의 셋업 코드를 필요로 함
    - 방대한 작업을 수행하면서 MR 태스크가 필요해지면 중간 과정의 데이터를 로컬 디스크에 써야 했다. 이는 속도의 문제로 이어짐
    - 일반적인 배치 처리를 위해서는 적당하지만 머신러닝, 스트리밍, 다른 워크로드와 연계해 사용하기에는 한계가 있음
  - 이래서 관련 에코시스템들이 등장함. (HIVE, Storm, Impala, Giraph, Drill, Mahout 등)
- AMP 랩에서의 스파크 초창기
  - UC 버클리 연구원들 (하둡 MR 작업에 참여해본)이 Spark 프로젝트에 도전을 시작함
  - Spark 초기 데모에서는 하둡 MR보다 10~20배 정도 빨랐음
  - 더 높은 장애 내구성, 병렬성, 중간 결과를 메모리에 저장, 다양한 언어 제공
  - 원 저작자들과 연구원들은 Spark를 아파치 재단에 이관하고, Databricks를 만들었음
  - 2014년 5월 Spark 1.0을 릴리스함.

## 아파치 스파크란 무엇인가?
- 대규모 분산 데이터 처리를 하기 위해 설계된 통합형 엔진
- 중간 연산을 위해 메모리 저장소를 지원하여 MR보다 훨씬 빠르게 동작함
- ML, SQL, 스트리밍, GraphX등 다양한 API들로 이루어짐
- Spark 설계 철학에는 속도, 사용 편리성, 모듈성, 확장성 4가지가 있음
- 속도
  - CPU, 메모리의 성능이 향상되면서 Spark는 더 많은 빛을 봄
  - Spark는 DAG로 수덩되어 효율적인 연산 그래프를 만들어서 클러스터의 워커 노드 위에서 병렬 수행될 수 있도록 해준다.
  - 모든 결과는 메모리에 유지되며, 디스크 I/O를 제한적으로 사용하므로 성능이 크게 향상된다.
- 사용 편리성
  - Spark는 데이터 프레임이나 데이터세트 같은 고수준 데이터 추상화 계층 아래에 분산 데이터 세트 (RDD, Resilient Distributed Dataset)라 불리는 자료구조를 구축하여 단순성을 실현함
  - 연산의 종류로서 트랜스포메이션과 액션의 집합을 제공
- 모듈성
  - Spark 연산은 다양한 워크로드에 적용 가능하며 여러 프로그래밍 언어로 표현할 수 있다. (Scala, Java, Python, SQL, R)
  - 핵심 컴포넌트로는 SQL, 스트리밍, MLlib, GraphX가 있음
  - 하나의 스파크 애플리케이션을 작성함으로써 모든 것이 실행 가능해짐.
- 확장성
  - 스파크는 저장보다는 빠른 병렬 연산 엔진에 초점이 맞춰져있다. 이는 수많은 데이터 소스에서 데이터를 읽어 들여 메모리에서 처리 가능하다는 의미다.

## 통합된 분석
- 통합은 스파크에 있어서 설계 철학과 진화를 나타내는 핵심 개념이다.
- 단일화된 스택으로의 아파치 컴포넌트
  - 네 개의 다양한 워크로드를 위한 라이브러리로 스파크 SQL, MLlib, 정형화 스트리밍, GraphX를 제공한다.
  - API를 써서 스파크 애플리케이션을 만들면 스파크 코어 엔진이 적절한 DAG로 변환해 실행하게 된다.
  - 그러므로 어떤 프로그래밍언어를 작성하여 정형화 API를 사용하더라도 실제 코드는 바이트코드로 변환되어 클러스터 전체에 나뉘어 워커 노드의 JVM에서 실행된다.
  - 스파크 SQL
    - 구조화된 데이터와 잘 동작한다. RDBMS 테이블이나 구조화된 데이터 파일 포맷에서 데이터를 읽어들일 수 있으며 영구적이거나 임시적인 테이블을 만들 수 있다.
    - ANSI SQL 2003 표준과 호환됨.
  - 스파크 MLlib
    - 머신러닝 알고리즘들을 포함한 라이브러리가 들어 있다.
    - 라이브러리의 성능은 스파크 2.x대의 엔진 개선 후 비약적으로 상승했다.
    - 특성들을 추출하고 변형하고 파이프라인을 구축하고 배포하는 동안 모델을 보존해준다.
  - 스파크 정형화 스트리밍
    - 스파크 2.0은 연속적인 스트리밍 모델과 정형화 스트리밍 API를 소개함
    - 정형화 스트리밍 모델의 하부에는 스파크 SQL 엔진이 장애 복구와 지연 데이터의 모든 측면을 관리하면서 쉽게 스트리밍 애플리케이션을 작성하도록 해준다.
    - 2.x와 3.0에서는 카프카, 키네시스, HDFS 기반 저장소나 클라우드 저장소 등으로 스트리밍 데이터 범위도 확장되었다.
  - GraphX
    - 그래프를 조작하고 그래프 병렬 연산을 수행하기 위한 라이브러리다.
- 아파치 스파크의 분산 실행
  - 하나의 스파크 애플리케이션은 스파크 클러스터의 병렬 작업들을 조율하는 하나의 드라이버 프로그램으로 이루어짐
  - 스파크 드라이버
    - SparkSession 객체를 초기화하는 책임을 가진 애플리케이션의 일부
    - 클러스터 매니저와 통신하며 필요한 자원을 요청(CPU, 메모리)
    - 모든 스파크 작업을 DAG 연산 형태로 변환하고 스케줄링
    - 각 실행 단위를 태스크로 나누어 Executors에게 분배
  - SparkSession
    - 스파크 2.0에서 SparkSession은 모든 스파크 연산과 데이터에 대한 통합 연결 채널이 되었음.
    - SparkContext, SQLContext, HiveContext, SparkConf, StreamingContext 등을 합쳐 놓음.
    - JVM 실행 파라미터들을 만들고 데이터 프레임이나 데이터세트를 정의하고 데이터 소스에서 데이터를 읽고, 메타데이터에 접근하고 스파크 SQL 질의를 실행함
    - ```scala
      import org.apache.spark.sql.SparkSession
      val spark = SparkSession.builder
                                            .appName("LearnSpark")
                                            .config("spark.sql.shuffle.partitions", 6)
                                            .getOrCreate()
      val people = spark.read.json("...")
      val resultsDF = spark.sql("SELECT city, pop, state, zip FROM table_name")
  - 클러스터 매니저
    - 스파크 애플리케이션이 실행되는 클러스터에서 자원을 관리 및 할당하는 책임
    - standalone, YARN, Mesos, Kubernetes를 지원함
  - 스파크 이그제큐터
    - 클러스터의 각 워커 노드에서 동작한다.
    - 드라이버 프로그램과 통신하며 워커에서 태스크를 실행하는 역할
  - 배포 모드
    - 스파크가 다양한 배포 모드를 지원함
    - |모드|스파크 드라이버|스파크 이그제큐터| 클러스터 매니저                                                    |
      |-----|---|-------------------------------------------------------------|------------|
      |로컬|랩톱이나 단일 서버 같은 머신에서 단일 JVM 위에서 실행|드라이버와 동일한 JVM 위에서 동작| 동일한 호스트에서 실행                                                |
      |단독|클러스터의 아무 노드에서나 실행|클러스터의 각 노드가 자체적인 이그제큐터 JVM을 실행| 클러스터의 아무 호스트에서나 할당 가능                                       |
      |얀(클라이언트)|클러스터 외부의 클라이언트에서 동작|얀의 노드매니저의 컨테이너| 얀의 리소스 매니저가 얀의 애플리케이션 마스터와 연계하여 노드 매니저에 이그제큐터를 위한 컨테이너들을 할당 |
      |얀(클러스터)|얀 애플리케이션 마스터에서 동작|얀(클라이언트) 모드와 동일|얀(클라이언트) 모드와 동일|
      |쿠버네티스|쿠버네티스 팟에서 동작|각 워커가 자신의 팟 내에서 실행|쿠버네티스 마스터|
  - 분산 데이터와 파티션
    - 실제 물리적인 데이터는 HDFS나 클라우드 저장소에 존재하는 파티션이 되어 저장소 전체에 분산된다.
    - 데이터가 파티션으로 되어 물리적으로 분산되면서 스파크는 각 파티션을 고수준에서 논리적인 데이터 추상화로 바라본다.
    - 파티셔닝은 효과적인 병렬 처리를 가능하게 해준다. 데이터를 조각내어 청크나 파티션으로 분산해 저장하는 방식은 스파크 이그제큐터가 네트워크 사용을 최소화하며 가까이 있는 데이터만 처리할 수 있도록 해준다.

