# 아파치 스파크로 머신러닝 파이프라인 관리, 배포 및 확장
* MLFlow를 사용하여 모델 트래킹, 재현 및 배포

<br>

## 모델 관리
* 모델의 성능을 재현하고 추적할 수 있는지 확인해야 함.
* 재현성 : 머신러닝 솔루션의 종단 간 모델 자체를 재현할 수 있어야 함.

<br>

**라이브러리 버전 관리**
* 어떤 라이브러리 버전을 이용했는지 명시하지 않으면 최신 버전이 설치되면서 코드가 망가지게 됨.

**데이터 진화**
* 처음 모델을 빌드하고 어느 정도의 기간이 지난 후 재현하려고 시도하지만 데이터 구조나 형태가 변경되어 에러발생할 수 있음

**실행 순서**
* 데이터 사이언티스트는 순서를 중요하지 않게 개발할 수 있기에 (Jupyter Notebook이라고 하면 순서를 왔다갔다할 수 있음) 결과를 재현하는 것은 어려움.

**병렬 작업**
* GPU는 많은 작업을 병렬로 실행하는데 순서가 항상 보장되는 것은 아니므로 비결정적일 수 있음.

<br>

* 파트너와 쉽게 공유할 수 있도록 모델을 관리하기 위한 표준을 갖는 것이 중요함.

<br>

## ML플로
* MLflow는 오픈소스 플랫폼
* 파이썬, R, Java/Scala의 인터페이스와 REST API를 제공함
* 다음의 4가지 주요 구성 요소가 있음.

**트래킹**
* 매개변수, 메트릭, 코드 버전 등 여러 아티팩트를 기록하는 API를 제공

**프로젝트**
* 데이터 과학 프로젝트 및 해당 종속성을 패키징하는 표준화 형식

**모델**
* 다양한 실행 환경에 배포하기 위해 모델을 패키징하는 표준화된 형식

**레지스트리**
* 중앙 저장소에서 모델을 저장, 주석 달기, 검색 그리고 관리함.

<br>

* 설치를 위해서는 `pip install mlflow` 를 실행하면 됨.

<br>

### 트래킹
* ML플로 트래킹은 학습을 수행하는 라이브러리 및 환경에 구애받지 않는 로깅 API
* ML플로 트래킹 서버는 많은 실험을 호스팅할 수 있음. 트래킹 서버에 기록할 수 있는 몇 가지 사항
* 매개변수 : 코드에 대한 키/값 입력
* 메트릭 : 숫자값 (RMSE 또는 정확도 값 같은 숫자)
* artifact : 파일, 데이터 및 모델
* 메타데이터 : 실행된 소스 코드
* 모델 : 학습한 모델

```python
from pyspark.ml import Pipeline
from pyspark.ml.feature import StringIndexer, VectorAssembler
from pyspark.ml.regression import RandomForestRegressor
from pyspark.ml.evaluation import RegressionEvaluator

filePath = "LearningSparkV2-master/databricks-datasets/learning-spark-v2/sf-airbnb/sf-airbnb-clean.parquet/"
airbnbDF = spark.read.parquet(filePath)
(trainDF, testDF) = airbnbDF.randomSplit([.8, .2], seed=42)

categoricalCols = [field for (field, dataType) in trainDF.dtypes if dataType == "string"]
indexOutputCols = [x + "Index" for x in categoricalCols]
stringIndexer = StringIndexer(inputCols=categoricalCols, outputCols=indexOutputCols, handleInvalid="skip")

numericCols = [field for (field, dataType) in trainDF.dtypes if ((dataType == "double") & (field != "price"))]
assemblerInputs = indexOutputCols + numericCols
vecAssembler = VectorAssembler(inputCols=assemblerInputs, outputCol="features")

rf = RandomForestRegressor(labelCol="price", maxBins=40, maxDepth=5, numTrees=100, seed=42)
pipeline = Pipeline(stages=[stringIndexer, vecAssembler, rf])

import mlflow
import mlflow.spark
import pandas as pd

with mlflow.start_run(run_name="random-forest") as run:
    mlflow.log_param("num_trees", rf.getNumTrees())
    mlflow.log_param("max_depth", rf.getMaxDepth())

    # 로그 모델
    pipelineModel = pipeline.fit(trainDF)
    mlflow.spark.log_model(pipelineModel, "model")

    # 로그 메트릭
    predDF = pipelineModel.transform(testDF)
    regressionEvaluator = RegressionEvaluator(predictionCol="prediction", labelCol="price")
    rmse = regressionEvaluator.setMetricName("rmse").evaluate(predDF)
    r2 = regressionEvaluator.setMetricName("r2").evaluate(predDF)
    mlflow.log_metrics({"rmse": rmse, "r2": r2})

    # 아티팩트
    rfModel = pipelineModel.stages[-1]
    pandasDF = (pd.DataFrame(list(zip(vecAssembler.getInputCols(), rfModel.featureImportances)),
                             columns=["feature", "importance"]).sort_values(by="importance", ascending=False))

    pandasDF.to_csv("feature-importance.csv", index=False)
    mlflow.log_artifact("feature-importance.csv")
```

## MLlib을 사용한 모델 배포 옵션
* 배치, 스트리밍, 실시간 모델에 따라 처리량, 지연시간은 다르다.

|      |처리량|지연시간|애플리케이션 예제|
|------|-|-|-|
| 배치   |높음|높음|고객 이탈 예측
| 스트리밍 |중간|중간|동적 가격 책정|
| 실시간  |낮음|낮음|온라인 광고 입찰|



* 배치
  * 가장 저렴하고 쉬운 배포 옵션
  * 다음 예측 배치를 생성하기 위해 지연 시간이 있음 
* 스트리밍
  * 처리량과 대기 시간 간의 적절한 균형을 제공
  * 정형화 스트리밍을 사용하는 경우 배치와 동일하기에 두 옵션 사이를 오갈 수 있음
* 실시간 
  * 처리량보다 대기 시간을 우선시함
  * 로드 밸런싱을 지원해야 하며 수요가 급증하는 경우 확장할 수 있어야 함.

<br>

### 배치
* 머신러닝 모델 배포의 대부분 사용 사례
* 일반 작업을 실행하여 예측을 생성하고 결과를 다운스트림에서 소비할 수 있도록 저장
* 배치 배포 시 염두해야할 사항들
  * 얼마나 자주 예측을 생성할 것인가? --> 많은 예측을 일괄 처리하면 더 높은 처리량을 얻을 수 있지만 그만큼 시간이 길어짐
  * 얼마나 자주 모델을 재학습할 것인가? --> MLlib은 모델을 다시 훈련시키려면 처음부터 다시 훈련해야 한다.
  * 모델을 어떻게 버전화할 것인가? --> ML플로 레지스트리를 이용해서 모델을 트래킹하고 전하환는 방식을 제어할 수 있음. UI를 사용하여 모델을 관리

<br>

### 스트리밍
* 들어오는 데이터에 대한 추론을 지속적으로 수행
* 배치 보다 유지 관리 및 모니터링이 더 복잡하지만 대기 시간이 짧음
* 스파크로는 배치를 스트리밍으로 변환이 쉬움. 유일한 차이는 `spark.read()` 대신 'spark.readStream()'을 사용해야 함.
* 스트리밍 잡이기 때문에 스키마를 먼저 정의해야 함.
```python
# 저장된 모델을 로드
pipelineModel = mlflow.spark.laod_model(f"runs:/{run_id}/model")

# 스트리밍 데이터를 셋업
repartitionedPath = "LearningSparkV2-master/databricks-datasets/learning-spark-v2/sf-airbnb/sf-airbnb-clean-100p.parquet/"
schema = spark.read.parquet(repartitionedPath).schema

streamingData = (spark.readStream.schema(schema)
                                 .option("maxFilesPerTrigger", 1)
                                 .parquet(repartitionedPath))

streamPred = pipelineModel.transform(streamingData)
```

<br>

### 실시간 추론을 위한 모델 내보내기 패턴
* 적은 수의 레코드로 예측을 수행하면 로드밸런싱과 지리적 위치와 싸워야 함
* 스파크에서 모델을 내보내는 방법은 파이썬, C 등으로 모델을 다시 구현하는 것. (모든 피처 엔지니어링 및 전처리 단계를 함께 내보내는 것은 번거롭다)
* ONNX (Open Neural Network Exchange)는 개발자가 라이브러리와 언어 사이를 전환할 수 있도록 하는 도구
* MLlib 모델을 내보내는 대신 XGBoost 같은 써드파티 라이브러리를 이용
* XGBoost : 배포가 쉽다, 모델을 추출하고 파이썬으로 비스파크 모델로 저장 가능

<br>

## 비MLlib 모델에 스파크 활용
*